# -*- coding: utf-8 -*-
"""KonigsbergProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iBvJihw4hU0Ssq6cOKvEJJVVIpry9qwK
"""

# !pip install pytorch_metric_learning

# from pytorch_metric_learning.losses import TripletMarginLoss
# from pytorch_metric_learning.distances import CosineSimilarity

import torch
import torch.nn as nn

from torch.utils.data import DataLoader, Dataset
from torch.optim import Adam
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import resnet18

import numpy as np
import pandas as pd

import random

from tqdm.notebook import tqdm

import os
from PIL import Image

import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""# Data split

Link to row data
"""

data_path = '/content/drive/MyDrive/Konigsberg Project/Data'

"""Links to supporting folders"""

small_classes_path = '/content/drive/MyDrive/Konigsberg Project/Small Classes'
test_data_path = '/content/drive/MyDrive/Konigsberg Project/Test Data'
extra_classes_path = '/content/drive/MyDrive/Konigsberg Project/Extra Classes'

"""## Move small folders

Define sufficient folder size
"""

sufficient_size = 8

"""Small folders recognition and extraction"""

for folder_name in os.listdir(data_path):
    folder_path = os.path.join(data_path, folder_name)
    folder_size = len(os.listdir(folder_path))
    if folder_size < sufficient_size:
        os.rename(folder_path, os.path.join(small_classes_path, folder_name))
        print(f"{folder_size}-sized folder {folder_name} of moved successfully from {data_path} to {small_classes_path}\n")

"""## Train-Validation data split

Define the splitting function. Two additional folders are used:
- **Extra classes** &mdash; for classes not considered in the initial training of the model; used to test cases when the model receives an image from the user with an unknown architectural object.
- **Test data** &mdash; for data used to test the model for its ability to recognize architectural objects that are known to it. Contains the same folders as **Data**, from which the **α** images of each class are extracted.
"""

def train_val_split(data_path, test_data_path, extra_classes_path, alpha=0.2, rest_size=5):

    folders = os.listdir(data_path)
    extra_folders = np.random.choice(folders,
                                     size=rest_size,
                                     replace=False)

    for folder_name in extra_folders:
        os.rename(os.path.join(data_path,
                               folder_name),
                  os.path.join(extra_classes_path,
                               folder_name))
        print(f"Folder {folder_name} moved successfully from {data_path} to {small_classes_path}\n")

    train_folders = list(set(folders) - set(extra_folders))

    for folder_name in train_folders:
        new_folder_path = os.path.join(test_data_path,
                                       folder_name)
        os.mkdir(new_folder_path)

        folder_path = os.path.join(data_path,
                                   folder_name)
        folder_list = os.listdir(folder_path)
        folder_size = len(folder_list)
        test_folder_size = int(np.floor(alpha * folder_size))

        test_folder_list = np.random.choice(folder_list,
                                            size=test_folder_size,
                                            replace=False)

        for img_name in test_folder_list:
            os.rename(os.path.join(folder_path,
                                   img_name),
                      os.path.join(new_folder_path,
                                   img_name))

train_val_split(data_path, test_data_path, extra_classes_path)

"""# Dataset preparation"""

folder_path = "/content/drive/MyDrive/Konigsberg Project"

train_data_path = folder_path + "/Data"
test_data_path = folder_path + "/Test Data"

# small_classes_path = '/content/drive/MyDrive/Konigsberg Project/Small Classes'
# extra_classes_path = '/content/drive/MyDrive/Konigsberg Project/Extra Classes'

class ResizeAndPadSquare():
    def __init__(self, img_size=224):
        self.img_size = img_size

    def __call__(self, image):
        width, height = image.size

        if width > height:
            new_width = self.img_size
            new_height = int(self.img_size * height / width)
        else:
            new_width = int(self.img_size * width / height)
            new_height = self.img_size

        resized_image = transforms.Resize((new_height, new_width))(image)

        pad_width = self.img_size - new_width
        left_pad = pad_width // 2
        right_pad = pad_width - left_pad

        pad_height = self.img_size - new_height
        up_pad = pad_height // 2
        down_pad = pad_height - up_pad

        padded_image = transforms.Pad((left_pad, up_pad, right_pad, down_pad))(resized_image)

        return padded_image

class Triple():
    def __call__(self, image):
      return image.repeat(3, 1, 1)

# class ReshapeAndTriple():
#     def __call__(self, image):
#       reshaped_image = image.permute(1, 2, 0)
#       tripled_image = reshaped_image.repeat(1, 1, 3)

#       return tripled_image

img_size = 224

transform = transforms.Compose([
    transforms.Grayscale(),
    ResizeAndPadSquare(img_size=img_size),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
    Triple()
])

# class ToNormalized2DTensor():
#     def __call__(self, image):
#         image = transforms.ToTensor()(image)
#         image = transforms.Normalize((0.5,), (0.5,))(image)
#         return image[0]

# transform = transforms.Compose([
#     transforms.Grayscale(),
#     ResizeAndPadSquare(),
#     ToNormalized2DTensor()
# ])

train_data = ImageFolder(train_data_path, transform)

# dir(train_data)
# train_data.targets[2521]

img_id = 999

img = train_data[img_id][0]
# print(img[:, :, 0])
print(img.shape)
print(train_data.classes[train_data[img_id][1]], end='\n\n')
plt.imshow(img[2].numpy(), cmap='gray')





train_embeddings = []
train_embeddings_np = pd.read_csv(folder_path + "/train_embeddings.csv").to_numpy()
train_embeddings = torch.tensor(train_embeddings_np)

train_labels = []
train_labels_np = pd.read_csv(folder_path + "/train_labels.csv").to_numpy()
train_labels_np = train_labels_np.reshape(train_labels_np.shape[0])
train_labels = torch.tensor(train_labels_np)

test_embeddings = []
test_embeddings_np = pd.read_csv(folder_path + "/test_embeddings.csv").to_numpy()
test_embeddings = torch.tensor(test_embeddings_np)

test_labels = []
test_labels_np = pd.read_csv(folder_path + "/test_labels.csv").to_numpy()
test_labels_np = test_labels_np.reshape(test_labels_np.shape[0])
test_labels = torch.tensor(test_labels_np)

!pip install faiss-cpu --no-cache
import faiss

def most_frequent_elements(arr):
    most_frequent = []
    for row in arr:
        unique, counts = np.unique(row, return_counts=True)
        max_count_index = np.argmax(counts)
        most_frequent.append(unique[max_count_index])
    return np.array(most_frequent)

num_classes = 70

index = faiss.IndexFlatIP(num_classes)
print(index.ntotal)
index.add(train_embeddings)
print(index.ntotal)

len("Глубокое обучение является молодым разделом машинного обучения. Оно возникло в качестве альтернативы классическому машинному обучению ещё на заре данной науки в середине 20 века. Однако активное развитие новая область получила лишь в 21 веке, когда заметно выросла производительность компьютеров в задачах математических вычислений. Глубокое обучение действительно является преемником классических методов. Как и предшественник, новый раздел машинного обучения точно так же подразумевает построение компьютерной модели, способной достаточно эффективно решать некоторую поставленную задачу. Однако стоит отметить основную особенность глубокого обучения, которая долгое время не позволяла проводить успешные исследования эффективности его методов. Новые модели подразумевалось строить таким образом, чтобы они преобразовывали каждый элемент из набора данных в некоторую сущность. Таким образом, глубокое обучение представляет собой класс методов машинного обучения, работа которых заключается в построении представлений. Возникает вопрос, зачем вообще был нужен новый подход? Почему нельзя было обойтись более простыми и понятными методами классического машинного обучения? На самом деле нетрудно понять, что базовые методы хорошо работают только для сильно ограниченного набора задач. Такая проблема существовала с самого рождения данной науки. Когда возникла потребность предсказывать ответы в задачах со сложными зависимостями, где не получается эффективно построить модели линейной или логистической регрессии, были предложены концепции дерева и ансамблей. В результате расширения данных идей классическое машинное обучение достигло вершины своего развития в лице градиентного бустинга. Этот метод до сих пор является самым популярным и эффективным среди тех, что используются в задачах с числовыми наборами данных. Для ответа на вопрос о причинах возникновения совершенно нового подхода стоит в очередной раз вспомнить, что из себя представляет машинное обучение в своей основе. Оно было задумано как класс методов, каждый из которых способен с высокой точностью выявлять закономерности в некотором наборе данных. При этом в общем случае не требовалось иметь строгого понимания, как именно работает произвольный метод. То есть, в изначальной концепии модель машинного обучения представлялась в виде чёрного ящика, который принимает данные на вход и выдаёт предсказанные ответы на выход (рис. 1)".split())

# img_id = 3
neighbor_count = 5

R, I = index.search(test_embeddings, neighbor_count)
print(I)
print(R)
# print()
# print(test_labels[img_id])
# print(train_labels[I][0])

neighbor_classes = train_labels[I].numpy()
predicted_labels = most_frequent_elements(neighbor_classes)
print(np.round(sum(predicted_labels == test_labels_np) / len(test_labels), 2))

D2 = 1 / ((1 - np.array(R[0])) / 2)**2
print(D2)
D = sum((2 * (train_labels[I][0] == test_labels[img_id]).numpy().reshape((neighbor_count,)) - 1) * D2) / sum(D2)
D





# model = resnet18(pretrained=True)

model = resnet18()

num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(train_data.classes))

# Load the model state dictionary
state_dict = torch.load(folder_path + "/my_model_weights.pth")

# Load the state dictionary into the model
model.load_state_dict(state_dict)

# loss_func = TripletMarginLoss(margin=0.2, distance=CosineSimilarity())
optimizer = Adam(model.parameters(), lr=0.001)
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device
model.to(device)

class ArchitectureModel():
    def __init__(self, device, transform, loss_func, optimizer, archive_path=None, model_path=None, model_class=None):
        self.device = device
        self.transform = transform
        self.loss_func = loss_func
        self.optimizer = optimizer
        self.archive_path = archive_path
        self.archive = ImageFolder(archive_path, self.transform)
        self.model_path = model_path
        if model_path is not None:
            self.model = model_class
            state_dict = torch.load(model_path)
            self.model.load_state_dict(state_dict)
            num_ftrs = model.fc.in_features
            self.model.fc = nn.Linear(num_ftrs, len(train_data.classes))
            self.model.to(self.device)

    def train(self, train_loader):
        pass

    def test(self, test_loader):
        assert self.train_data is not None
        pass

    def predict(self, image_path):
        assert train_data is not None
        with Image.open(image_path) as img:
            img = self.transform(img)
            img = img.unsqueeze(0)
            img = img.to(self.device)
            model.eval()
            with torch.no_grad():
                output = model(img)
                predicted_class = torch.argmax(output, dim=1).item()
        return predicted_class

    def get_some_pictures(self, class_id, count=5):
        assert self.archive is not None
        class_name = self.archive.classes[class_id]
        class_path = os.path.join(self.archive_path, class_name)
        paths = []
        for img_name in np.random.choice(os.listdir(class_path), size=count, replace=False):
            paths.append(os.path.join(class_path, img_name))
        return paths

solver = ArchitectureModel(device, transform, model, loss_func, optimizer, train_data_path)

image_id = 2070

image_path, image_class = train_data.samples[image_id]
print("Реальный класс:", image_class)

class_id = solver.predict(image_path)
print("Предсказанный класс:", class_id, '\n')

images = solver.get_some_pictures(class_id)
print("Отобранные изображения:", *images, sep='\n')

with Image.open(image_path) as image:
    img = transform(image)
    plt.imshow(img[2].numpy(), cmap='gray')

with Image.open(images[1]) as image:  # Можно выбрать индекс от 0 до 4
    img = transform(image)
    plt.imshow(img[2].numpy(), cmap='gray')





















image_path, image_class = train_data.samples[1200]
print(image_class)

with Image.open(image_path) as image:
    img = transform(image)
    # plt.imshow(img[2].numpy(), cmap='gray')
    img = img.unsqueeze(0)
    img = img.to(device)
    print(type(img))
    # print(img[:, :, 0])
    model.eval()
    with torch.no_grad():
        output = model(img)
        print(output.shape)
        predicted_class = torch.argmax(output, dim=1)
        print(predicted_class.item())

for param in model.parameters():
    param.requires_grad = False

for param in model.layer4.parameters():
    param.requires_grad = True

for param in model.fc.parameters():
    param.requires_grad = True

for name, param in model.named_parameters():
    print(f'Layer: {name} - Requires gradient? {param.requires_grad}')

num_epochs = 10

for epoch in tqdm(range(num_epochs)):
    model.train()
    running_loss = 0.0
    for inputs, labels in tqdm(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')

# Get the model's state dictionary
model_state_dict = model.state_dict()

# Save the state dictionary to a file
torch.save(model_state_dict, folder_path + "/my_model_weights.pth")

train_embeddings, train_labels = [], []

model.eval()
with torch.no_grad():
    for inputs, labels in tqdm(train_loader):
        inputs = inputs.to(device)
        batch_embeddings = nn.functional.normalize(model(inputs))
        for embedding in batch_embeddings:
            train_embeddings.append(torch.reshape(embedding, (1, len(train_data.classes))))
        for label in labels:
            train_labels.append(label.item())

train_embeddings = torch.cat(train_embeddings, 0)
train_labels = torch.tensor(train_labels)

# width = len(train_embeddings[0])

# for i in range(len(train_embeddings)):
#     train_embeddings[i] = torch.reshape(train_embeddings[i], (1, width))

train_embeddings

train_embeddings_np = train_embeddings.cpu().numpy()
train_embeddings_df = pd.DataFrame(train_embeddings_np)
train_embeddings_df.to_csv(folder_path + "/train_embeddings.csv", index=False)

train_labels_np = train_labels.cpu().numpy()
train_labels_df = pd.DataFrame(train_labels_np)
train_labels_df.to_csv(folder_path + "/train_labels.csv", index=False)







metric = CosineSimilarity()

a = torch.tensor([1.0, 0.0, 0.0])
b = torch.tensor([1000.0, 100.0, 45.0])
metric(a.unsqueeze(0), b.unsqueeze(0))

n = len(train_embeddings)
distances = [[1.0, 1.0] for _ in range(n)]

for i in tqdm(range(n - 1)):
    for j in range(i + 1, n):
        distance = (1 - metric(train_embeddings[i][0].unsqueeze(0), train_embeddings[j][0].unsqueeze(0))) / 2.0
        distance = distance.item()
        if train_embeddings[i][1] == train_embeddings[j][1]:
            distances[i][0] = min(distances[i][0], distance)
            distances[j][0] = min(distances[j][0], distance)
        else:
            distances[i][1] = min(distances[i][1], distance)
            distances[j][1] = min(distances[j][1], distance)

distances.sort(key=lambda x: x[0])

min_relative_distances, min_stranger_distances = [], []
for a, b in distances:
    min_relative_distances.append(a)
    min_stranger_distances.append(b)

fig = plt.figure()
plt.plot(min_relative_distances, label="Min relative distance")
plt.plot(min_stranger_distances, label="Min stranger distance")
plt.legend()





test_data = ImageFolder(test_data_path, transform)

test_loader = DataLoader(test_data, batch_size=32, shuffle=True)

test_embeddings, test_labels = [], []

model.eval()
with torch.no_grad():
    for inputs, labels in tqdm(test_loader):
        inputs = inputs.to(device)
        batch_embeddings = nn.functional.normalize(model(inputs))
        for embedding in batch_embeddings:
            test_embeddings.append(torch.reshape(embedding, (1, len(train_data.classes))))
        for label in labels:
            test_labels.append(label.item())

test_embeddings = torch.cat(test_embeddings, 0)
test_labels = torch.tensor(test_labels)

# test_embeddings_np = test_embeddings.cpu().numpy()
# test_embeddings_df = pd.DataFrame(test_embeddings_np)
# test_embeddings_df.to_csv(folder_path + "/test_embeddings.csv", index=False)

test_labels_np = test_labels.cpu().numpy()
test_labels_df = pd.DataFrame(test_labels_np)
test_labels_df.to_csv(folder_path + "/test_labels.csv", index=False)

